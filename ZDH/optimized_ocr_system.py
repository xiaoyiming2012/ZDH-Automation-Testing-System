#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„OCRç³»ç»Ÿ
åŸºäºæµ‹è¯•ç»“æœé€‰æ‹©æœ€ä½³çš„é¢„å¤„ç†æ–¹æ³•å’Œå‚æ•°é…ç½®
"""

import cv2
import numpy as np
import easyocr
from PIL import Image, ImageGrab, ImageEnhance, ImageFilter
import time
from pathlib import Path

class OptimizedOCRSystem:
    """ä¼˜åŒ–çš„OCRç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        print("æ­£åœ¨åˆå§‹åŒ–ä¼˜åŒ–çš„OCRç³»ç»Ÿ...")
        
        # OCRé…ç½®
        self.ocr_reader = None
        self._init_ocr()
        
        # åŸºäºæµ‹è¯•ç»“æœçš„æœ€ä½³é…ç½®
        self.optimized_config = {
            'preprocessing_method': 'enhance_sharpness',  # æœ€ä½³æ–¹æ³•
            'confidence_threshold': 0.6,  # é™ä½é˜ˆå€¼æé«˜å¬å›ç‡
            'resize_factor': 1.5,  # é€‚ä¸­çš„æ”¾å¤§å€æ•°
            'enhance_contrast': 1.3,  # é€‚ä¸­çš„å¯¹æ¯”åº¦å¢å¼º
            'enhance_sharpness': 1.3,  # é€‚ä¸­çš„é”åº¦å¢å¼º
            'denoise_enabled': True,  # å¯ç”¨é™å™ª
            'morphology_enabled': True  # å¯ç”¨å½¢æ€å­¦å¤„ç†
        }
        
        print("âœ… ä¼˜åŒ–çš„OCRç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def _init_ocr(self):
        """åˆå§‹åŒ–OCR"""
        try:
            self.ocr_reader = easyocr.Reader(['ch_sim', 'en'], gpu=False, verbose=False)
            print("âœ… OCRåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ OCRåˆå§‹åŒ–å¤±è´¥: {e}")
            self.ocr_reader = None
    
    def preprocess_image_optimized(self, image):
        """ä¼˜åŒ–çš„å›¾åƒé¢„å¤„ç†"""
        try:
            # è½¬æ¢ä¸ºPILå›¾åƒ
            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            
            # 1. é€‚åº¦æ”¾å¤§
            new_size = (int(pil_image.width * self.optimized_config['resize_factor']),
                       int(pil_image.height * self.optimized_config['resize_factor']))
            pil_image = pil_image.resize(new_size, Image.LANCZOS)
            
            # 2. å¢å¼ºå¯¹æ¯”åº¦
            enhancer = ImageEnhance.Contrast(pil_image)
            pil_image = enhancer.enhance(self.optimized_config['enhance_contrast'])
            
            # 3. å¢å¼ºé”åº¦ï¼ˆæœ€ä½³æ–¹æ³•ï¼‰
            enhancer = ImageEnhance.Sharpness(pil_image)
            pil_image = enhancer.enhance(self.optimized_config['enhance_sharpness'])
            
            # 4. é™å™ªå¤„ç†
            if self.optimized_config['denoise_enabled']:
                pil_image = pil_image.filter(ImageFilter.MedianFilter(size=3))
            
            # 5. å½¢æ€å­¦å¤„ç†
            if self.optimized_config['morphology_enabled']:
                gray_array = np.array(pil_image.convert('L'))
                kernel = np.ones((2, 2), np.uint8)
                gray_array = cv2.morphologyEx(gray_array, cv2.MORPH_CLOSE, kernel)
                pil_image = Image.fromarray(gray_array)
            
            # è½¬æ¢å›OpenCVæ ¼å¼
            processed_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            
            return processed_image
            
        except Exception as e:
            print(f"å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}")
            return image
    
    def recognize_text_optimized(self, image, target_text=None):
        """ä¼˜åŒ–çš„æ–‡æœ¬è¯†åˆ«"""
        if not self.ocr_reader:
            return []
        
        try:
            # ä¼˜åŒ–çš„é¢„å¤„ç†
            processed_image = self.preprocess_image_optimized(image)
            
            # OCRè¯†åˆ«
            results = self.ocr_reader.readtext(
                processed_image,
                detail=1,
                paragraph=False
            )
            
            # ç»“æœåå¤„ç†
            enhanced_results = []
            for bbox, text, confidence in results:
                # æ¸…ç†æ–‡æœ¬
                cleaned_text = self._clean_text(text)
                
                # æå‡ç½®ä¿¡åº¦
                boosted_confidence = self._boost_confidence(confidence, cleaned_text, target_text)
                
                # è®¡ç®—ä¸­å¿ƒç‚¹
                center = self._calculate_center(bbox)
                
                enhanced_results.append({
                    'bbox': bbox,
                    'original_text': text,
                    'cleaned_text': cleaned_text,
                    'confidence': confidence,
                    'boosted_confidence': boosted_confidence,
                    'center': center,
                    'area': self._calculate_area(bbox)
                })
            
            # æŒ‰æå‡åçš„ç½®ä¿¡åº¦æ’åº
            enhanced_results.sort(key=lambda x: x['boosted_confidence'], reverse=True)
            
            return enhanced_results
            
        except Exception as e:
            print(f"OCRè¯†åˆ«å¤±è´¥: {e}")
            return []
    
    def _clean_text(self, text):
        """æ¸…ç†æ–‡æœ¬"""
        if not text:
            return ""
        
        # å»é™¤å™ªå£°å­—ç¬¦
        noise_chars = ['|', '\\', '/', '-', '_', '=', '+', '*', '&', '^', '%', '$', '#', '@', '!']
        cleaned = text
        for char in noise_chars:
            cleaned = cleaned.replace(char, '')
        
        # å»é™¤å¤šä½™ç©ºæ ¼
        cleaned = ' '.join(cleaned.split())
        return cleaned.strip()
    
    def _boost_confidence(self, confidence, text, target_text=None):
        """æå‡ç½®ä¿¡åº¦"""
        boosted = confidence
        
        # åŸºäºæ–‡æœ¬é•¿åº¦æå‡
        if len(text) >= 3:
            boosted += 0.1
        
        # åŸºäºæ–‡ä»¶æ‰©å±•åæå‡
        if any(ext in text.lower() for ext in ['.txt', '.json', '.doc', '.pdf']):
            boosted += 0.15
        
        # åŸºäºæ–‡æœ¬è´¨é‡æå‡
        if text.isalnum():
            boosted += 0.1
        
        # åŸºäºç›®æ ‡åŒ¹é…æå‡
        if target_text and target_text.lower() in text.lower():
            boosted += 0.2
        
        return min(boosted, 1.0)
    
    def _calculate_center(self, bbox):
        """è®¡ç®—ä¸­å¿ƒç‚¹"""
        try:
            x1, y1 = bbox[0]
            x3, y3 = bbox[2]
            center_x = int((x1 + x3) / 2)
            center_y = int((y1 + y3) / 2)
            return (center_x, center_y)
        except:
            return (0, 0)
    
    def _calculate_area(self, bbox):
        """è®¡ç®—é¢ç§¯"""
        try:
            x1, y1 = bbox[0]
            x3, y3 = bbox[2]
            width = abs(x3 - x1)
            height = abs(y3 - y1)
            return width * height
        except:
            return 0
    
    def find_text_optimized(self, image, target_text, min_confidence=0.5):
        """ä¼˜åŒ–çš„æ–‡æœ¬æŸ¥æ‰¾"""
        results = self.recognize_text_optimized(image, target_text)
        
        for result in results:
            if (result['boosted_confidence'] >= min_confidence and 
                target_text.lower() in result['cleaned_text'].lower()):
                
                print(f"âœ… æ‰¾åˆ°ç›®æ ‡æ–‡æœ¬: {target_text}")
                print(f"   åŸå§‹æ–‡æœ¬: {result['original_text']}")
                print(f"   æ¸…ç†æ–‡æœ¬: {result['cleaned_text']}")
                print(f"   ç½®ä¿¡åº¦: {result['confidence']:.3f} -> {result['boosted_confidence']:.3f}")
                print(f"   ä½ç½®: {result['center']}")
                print(f"   é¢ç§¯: {result['area']}")
                
                return result['center']
        
        print(f"âŒ æœªæ‰¾åˆ°ç›®æ ‡æ–‡æœ¬: {target_text}")
        return None
    
    def get_detailed_analysis(self, image):
        """è·å–è¯¦ç»†çš„æ–‡æœ¬åˆ†æ"""
        results = self.recognize_text_optimized(image)
        
        # åˆ†æç»“æœ
        analysis = {
            'total_texts': len(results),
            'file_like_texts': [],
            'high_confidence_texts': [],
            'text_statistics': {}
        }
        
        for result in results:
            # æ–‡ä»¶æ ·æœ¬æ–‡æœ¬
            if self._looks_like_filename(result['cleaned_text']):
                analysis['file_like_texts'].append(result)
            
            # é«˜ç½®ä¿¡åº¦æ–‡æœ¬
            if result['boosted_confidence'] > 0.8:
                analysis['high_confidence_texts'].append(result)
            
            # æ–‡æœ¬é•¿åº¦ç»Ÿè®¡
            text_length = len(result['cleaned_text'])
            if text_length not in analysis['text_statistics']:
                analysis['text_statistics'][text_length] = 0
            analysis['text_statistics'][text_length] += 1
        
        return analysis
    
    def _looks_like_filename(self, text):
        """åˆ¤æ–­æ˜¯å¦åƒæ–‡ä»¶å"""
        if not text or len(text) < 2:
            return False
        
        # åŒ…å«æ–‡ä»¶æ‰©å±•å
        if any(ext in text.lower() for ext in ['.txt', '.json', '.doc', '.pdf', '.jpg', '.png']):
            return True
        
        # åŒ…å«æ•°å­—å’Œå­—æ¯çš„ç»„åˆ
        import re
        if re.search(r'[a-zA-Z].*\d|\d.*[a-zA-Z]', text):
            return True
        
        # é•¿åº¦é€‚ä¸­
        if 3 <= len(text) <= 50:
            return True
        
        return False

def main():
    """æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("ä¼˜åŒ–çš„OCRç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    ocr = OptimizedOCRSystem()
    
    # æˆªå–å±å¹•
    print("\nğŸ“¸ æˆªå–å±å¹•...")
    screenshot = ImageGrab.grab()
    screenshot_np = np.array(screenshot)
    screenshot_cv = cv2.cvtColor(screenshot_np, cv2.COLOR_RGB2BGR)
    print("âœ… å±å¹•æˆªå›¾å®Œæˆ")
    
    # è·å–è¯¦ç»†åˆ†æ
    print("\nğŸ” è·å–è¯¦ç»†æ–‡æœ¬åˆ†æ...")
    analysis = ocr.get_detailed_analysis(screenshot_cv)
    
    print(f"\nğŸ“Š åˆ†æç»“æœ:")
    print(f"  æ€»æ–‡æœ¬æ•°: {analysis['total_texts']}")
    print(f"  æ–‡ä»¶æ ·æœ¬æ–‡æœ¬æ•°: {len(analysis['file_like_texts'])}")
    print(f"  é«˜ç½®ä¿¡åº¦æ–‡æœ¬æ•°: {len(analysis['high_confidence_texts'])}")
    
    # æ˜¾ç¤ºæ–‡ä»¶æ ·æœ¬æ–‡æœ¬
    if analysis['file_like_texts']:
        print(f"\nğŸ“ æ–‡ä»¶æ ·æœ¬æ–‡æœ¬ (å‰10ä¸ª):")
        for i, item in enumerate(analysis['file_like_texts'][:10]):
            print(f"  {i+1}. '{item['cleaned_text']}' ä½ç½®: {item['center']}")
    
    # æµ‹è¯•æŸ¥æ‰¾ç‰¹å®šæ–‡æœ¬
    print(f"\nğŸ¯ æµ‹è¯•æŸ¥æ‰¾ 'info.json':")
    position = ocr.find_text_optimized(screenshot_cv, "info.json", min_confidence=0.4)
    
    if position:
        print(f"âœ… æˆåŠŸæ‰¾åˆ°ä½ç½®: {position}")
    else:
        print("âŒ æœªæ‰¾åˆ°ç›®æ ‡æ–‡æœ¬")
    
    print("\næµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()
